1 framework and requirements for cloud computing  
 
322  
the keywords "is recommended" indicate a requirement which is recommended but which is not absolutely 
required. thus this requirement need not be present to claim conformance. 
the keywords "can optionally" indicate an optional requirement which is permissible, without implying any 
sense of being recommended. this term is not intended to imply that th e vendor's implementation must 
provide the option and the feature can be optionally enabled by the network operator/service provider. 
rather, it means the vendor may optionally provide the feature and still claim conformance with the 
specification. 
in the body of this document and its annexes, the words shall, shall not, should, and may sometimes appear, 
in which case they are to be interpreted, respectively, as is required to, is prohibited from, is recommended, 
and can optionally. the appearance of such p hrases or keywords in an appendix or in material explicitly 
marked as informative are to be interpreted as having no normative intent. 
6 overview of big data 
6.1 introduction to big data 
with the rapid development of information and communications technology (ict), internet technologies and 
services, huge amounts of data are generated, transmitted and stored at an explosive rate of growth. data 
are generated by many sources and not only by sensors, cameras or network devices, but also by web pages, 
email systems and social networks as well as by many other sources. datasets are becoming so large and so 
complex or are arriving so fast that traditional data processing methods and tools are inadequate. efficient 
analytics of data within tolerable elapsed times becomes very challenging. the paradigm being developed to 
resolve the above issues is called big data. 
for the purpose of this recommendation it is understood, that within the big data ecosystem, data types 
include structured, semi -structured and unstructured data. structured data are often stored in databases 
which may be organized in different models, such as relational models, document models, key-value models, 
graph models, etc. semi -structured data does not conform to the formal structure of data models, but 
contain tags or markers to identify data. unstructured data do not have a pre -defined data model and are 
not organized in any defined manner. within all data types data can exist in formats, such as text, 
spreadsheet, video, audio, image, map, etc. 
big data are successfully used in many fields, if traditional methods and tools have become inefficient, where 
data processing is characterized by scale (volume), diversity (variety), high speed (velocity) and possibly other 
criteria like credibility (veracity) or business value. these characteristics, usually called the vs, can be 
explained as follows: 
– volume: refers to the amount of data collected, stored, analysed and visualized, which big data 
technologies need to resolve; 
– variety: refers to different data types and data formats that are processed by big data technologies; 
– velocity: refers to both how fast the data is being collected and how fast the data is processed by 
big data technologies to deliver expected results. 
note – additionally, veracity refers to the uncertainty of the data and value refers to the business results from the gains 
in new information using big data technologies. other vs can be considered as well.  
taking into account the above vs' described characteristics, big data technologies and services allow many 
new challenges to be resolved and also create more new opportunities than ever before: 
– heterogeneity and incompleteness: data processed using big data can miss some attributes or 
introduce noise in data transmission. even after data cleaning and error correction, some 
incompleteness and some errors in data are likely to rem ain. these challenges can be managed 
during data analysis. [b-cra-bdwp] 
– scale: processing of large and rapidly increasing volumes of data is a challenging task . using data 
processing technologies, the data scale challenge was mitigated by the evolution of processing and 
storage resources. nowadays however data volumes are scaling faster than resources can evolve. 
technologies such as parallel databases, in memory databases, non -sql databases and analytical 
algorithms allow this challenge to be resolved. 
